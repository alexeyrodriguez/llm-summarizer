Summary:
The paper introduces SoundStorm, a model for efficient parallel audio generation that addresses the challenges of generating long audio token sequences. SoundStorm utilizes a bidirectional attention-based Conformer trained to predict masked audio tokens, incorporating a parallel, non-autoregressive, confidence-based decoding scheme. By leveraging the hierarchical structure of audio tokens and a masking scheme for training and inference, SoundStorm achieves high-quality audio generation at a significantly faster speed compared to traditional autoregressive models. The model demonstrates the ability to synthesize natural dialogues and control speaker voices and content. SoundStorm's approach offers a promising solution for efficient and high-quality audio generation, showcasing advancements in the field of neural audio codecs and sequence-to-sequence modeling.