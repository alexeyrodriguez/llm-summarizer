Summary:
The paper titled "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions" introduces Tacotron 2, a neural network architecture for speech synthesis directly from text. The system consists of a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, followed by a modified WaveNet model acting as a vocoder to synthesize time-domain waveforms from those spectrograms. The model achieves a mean opinion score (MOS) comparable to professionally recorded speech. The paper validates design choices through ablation studies and demonstrates the impact of using mel spectrograms as conditioning input to WaveNet. By using this compact acoustic intermediate representation, the size of the WaveNet architecture is significantly reduced. The model combines the best aspects of previous approaches, simplifying the speech synthesis pipeline and generating natural-sounding speech that closely resembles human speech. The architecture includes a spectrogram prediction network and a WaveNet vocoder, with attention mechanisms and LSTM layers. The WaveNet vocoder is a modified version that uses a mixture of logistic distributions to generate waveform samples. The paper presents a detailed description of the model architecture and the training process, highlighting the effectiveness of the neural approach in speech synthesis.