Summary:
The paper introduces SPEAR-TTS, a multi-speaker text-to-speech (TTS) system that can be trained with minimal supervision. By splitting the TTS task into two sequence-to-sequence tasks - from text to high-level semantic tokens and from semantic tokens to low-level acoustic tokens - the system can be trained efficiently. The "speaking" module can be trained using abundant audio-only data, while the "reading" component can be trained with reduced parallel data through pretraining and backtranslation techniques. Speaker identity control is achieved through example prompting, allowing the system to generalize to unseen speakers with just a short sample. Experimental results show that SPEAR-TTS achieves competitive character error rates with state-of-the-art methods using only 15 minutes of parallel data, while maintaining naturalness and acoustic quality. The system leverages self-supervised audio representations for semantic and acoustic tokens, enabling diverse voice synthesis and high-quality speech generation. The approach significantly reduces data collection costs and has the potential to provide high-quality multi-speaker TTS for languages with limited resources.